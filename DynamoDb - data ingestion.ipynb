{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with AWS Dynamo DB using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamo DB Overview\n",
    "Amazon DynamoDB is a NoSQL database that supports key-value and document data models. It delivers single-digit millisecond performance at any scale. It's a fully managed, multiregion, multimaster, durable database with built-in security, backup and restore, and in-memory caching for internet-scale applications\n",
    "\n",
    "Click [here](https://aws.amazon.com/dynamodb/) for more information\n",
    "\n",
    "If you have an Amazon Free Tier account, you can use this notebook to create a **jobs1** table in the DynamoDB. Use it to insert and query the data from the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python and Dynamo DB\n",
    "\n",
    "We need to import **boto3** package to be able to work with Dynamo DB using Python\n",
    "\n",
    "Click [here](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.Python.html) for the boto3 Dynamo DB documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key, Attr\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a resource representing the Amazon DynamoDB\n",
    "\n",
    "We need to specify the following:\n",
    "1. resource name - \"dynamodb\"\n",
    "2. region name\n",
    "3. aws_access_key_id\n",
    "4. aws_secret_access_key\n",
    "\n",
    "I haven't added the access key or secret key in the script for security reasons. If you add them, the statement would look something like this\n",
    "dynamodb = boto3.resource(\"dynamodb\", region_name = \"us-west-1\", aws_access_key_id = \"XXX\", aws_secret_access_key = \"XXX\")\n",
    "\n",
    "Alternatively, one can set up the environment to contain the keys and utilize those environmental variables when creating the resouce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource(\"dynamodb\", region_name = \"us-west-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table with partition and sort keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DynamoDB has two kinds of primary keys. Other than these keys, the table is schemaless.\n",
    "1. Partition Key\n",
    "2. Sort Key\n",
    "\n",
    "These keys can be use to simluate the primary key and composite primary key concepts in relation database.\n",
    "1. Partition key - used as input to an internal hash function. The output from the hash function determines the partition in which the item will be stored. In a table that has only a partition key, no two items can have the same partition key value.\n",
    "\n",
    "2. Partition and Sort key - partition key value is used as input to an internal hash function. The output from the hash function determines the partition in which the item will be stored. All items with the same partition key value are stored together, in sorted order by sort key value. In a table that has a partition key and a sort key, it's possible for two items to have the same partition key value. However, those two items must have different sort key values.\n",
    "\n",
    "We also need to specify the read and write capacity units when creating the table. I have used 20 units for each in the example as the maximum limit available for AWS free tier is 25.\n",
    "\n",
    "* Read Capacity Units - One read capacity unit represents one strongly consistent read per second, or two eventually consistent reads per second, for an item up to 4 KB in size.\n",
    "\n",
    "* Write Capacity Units - One write capacity unit represents one write per second for an item up to 1 KB in size. If you need to write an item that is larger than 1 KB, DynamoDB must consume additional write capacity units.\n",
    "\n",
    "Click [here](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html) to learn more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **jobs1** table, we are creating a composite primary key using the job_title and a combined attribute of company, location information. As these three information uniquely identifies each item in the table. Since we can use only two attributes to create a unique identifier for each item in DynamoDB, we are combining the company name and job location data into a single value separated by an underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dynamodb.create_table(\n",
    "    TableName='jobs1',\n",
    "    KeySchema=[\n",
    "        {\n",
    "            'AttributeName': 'job_title',\n",
    "            'KeyType': 'HASH'\n",
    "        },\n",
    "        {\n",
    "            'AttributeName': 'company_location',\n",
    "            'KeyType': 'RANGE'\n",
    "        }\n",
    "    ],\n",
    "    AttributeDefinitions=[\n",
    "        {\n",
    "            'AttributeName': 'job_title',\n",
    "            'AttributeType': 'S'\n",
    "        },\n",
    "        {\n",
    "            'AttributeName': 'company_location',\n",
    "            'AttributeType': 'S'\n",
    "        },\n",
    "    ],\n",
    "    ProvisionedThroughput={\n",
    "        'ReadCapacityUnits': 20,\n",
    "        'WriteCapacityUnits': 20\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the table schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Table': {'AttributeDefinitions': [{'AttributeName': 'company_location', 'AttributeType': 'S'}, {'AttributeName': 'job_title', 'AttributeType': 'S'}], 'TableName': 'jobs1', 'KeySchema': [{'AttributeName': 'job_title', 'KeyType': 'HASH'}, {'AttributeName': 'company_location', 'KeyType': 'RANGE'}], 'TableStatus': 'ACTIVE', 'CreationDateTime': datetime.datetime(2020, 4, 2, 23, 8, 8, 5000, tzinfo=tzlocal()), 'ProvisionedThroughput': {'NumberOfDecreasesToday': 0, 'ReadCapacityUnits': 20, 'WriteCapacityUnits': 20}, 'TableSizeBytes': 0, 'ItemCount': 0, 'TableArn': 'arn:aws:dynamodb:us-west-1:764210939372:table/jobs1', 'TableId': 'e32a08ab-b994-4c00-b2b4-3b0f91991e59'}, 'ResponseMetadata': {'RequestId': 'EA345A830UL7GDBDMBF2NGA6Q7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'HTTPStatusCode': 200, 'HTTPHeaders': {'server': 'Server', 'date': 'Fri, 03 Apr 2020 06:08:12 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '585', 'connection': 'keep-alive', 'x-amzn-requestid': 'EA345A830UL7GDBDMBF2NGA6Q7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'x-amz-crc32': '4119862138'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "dynamoDBClient = boto3.client('dynamodb')\n",
    "table = dynamoDBClient.describe_table(\n",
    "    TableName='jobs1'\n",
    ")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select an existing table from the DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dynamodb.Table(\"jobs1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the job listing data collected from indeed website\n",
    "data1 = pd.read_csv(\"indeed_job_listings.csv\", usecols = [1, 2, 3, 4, 5, 6, 7, 8, 9], engine= 'python')\n",
    "\n",
    "# Creates the range key by combining company and location columns using a \"_\"\n",
    "data1[\"company_location\"] = data1[\"Company\"] + \"_\" + data1[\"City\"]\n",
    "\n",
    "# Renaming the columns of the dataframe\n",
    "data1.columns = [\"job_title\", \"company\", \"reviews\", \"description\", \"salary\", \"city\", \"state\", \"zip_code\", \"source\", \"company_location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>reviews</th>\n",
       "      <th>description</th>\n",
       "      <th>salary</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>source</th>\n",
       "      <th>company_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ABC</td>\n",
       "      <td>10 reviews</td>\n",
       "      <td>With one application you can be considered for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>ABC_Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>BCD</td>\n",
       "      <td>680 reviews</td>\n",
       "      <td>Cloud Hardware Infrastructure and Engineering ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>BCD_Redmond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML Data Associate</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>759 reviews</td>\n",
       "      <td>Basic Qualifications\\nBachelors degree or comm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>XYZ_Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>WXY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Looking for a Data Analyst to join our Strateg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>WXY_Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>DEF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Looking to add experienced and entry-level imp...</td>\n",
       "      <td>$65,553.00 to $120,000.00 /year</td>\n",
       "      <td>Marlborough</td>\n",
       "      <td>MA</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>DEF_Marlborough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           job_title company      reviews  \\\n",
       "0       Data Analyst     ABC   10 reviews   \n",
       "1   Business Analyst     BCD  680 reviews   \n",
       "2  ML Data Associate     XYZ  759 reviews   \n",
       "3       Data Analyst     WXY          NaN   \n",
       "4   Business Analyst     DEF          NaN   \n",
       "\n",
       "                                         description  \\\n",
       "0  With one application you can be considered for...   \n",
       "1  Cloud Hardware Infrastructure and Engineering ...   \n",
       "2  Basic Qualifications\\nBachelors degree or comm...   \n",
       "3  Looking for a Data Analyst to join our Strateg...   \n",
       "4  Looking to add experienced and entry-level imp...   \n",
       "\n",
       "                            salary         city state  zip_code  source  \\\n",
       "0                              NaN      Seattle    WA       NaN  Indeed   \n",
       "1                              NaN      Redmond    WA       NaN  Indeed   \n",
       "2                              NaN      Seattle    WA       NaN  Indeed   \n",
       "3                              NaN       Boston    MA    2116.0  Indeed   \n",
       "4  $65,553.00 to $120,000.00 /year  Marlborough    MA    1752.0  Indeed   \n",
       "\n",
       "  company_location  \n",
       "0      ABC_Seattle  \n",
       "1      BCD_Redmond  \n",
       "2      XYZ_Seattle  \n",
       "3       WXY_Boston  \n",
       "4  DEF_Marlborough  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the rows into json string\n",
    "data1 = data1.to_json(orient='records')\n",
    "\n",
    "# Convert json string to json object\n",
    "job_data = json.loads(data1, parse_float = Decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading data to the database using batch writer\n",
    "\n",
    "Batch write can be used to write data to the DynamoDB in batches instead of item by item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "with table.batch_writer(overwrite_by_pkeys=['job_title', 'company_location']) as batch:\n",
    "    for i in range(len(job_data)):\n",
    "        print(i)\n",
    "        batch.put_item(Item = job_data[i])\n",
    "        # wait time is used between each records to reduce the write frequency in the database\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add an item to the table\n",
    "\n",
    "The attributes that we mentioned as partition and sort keys when creating the table must be included when adding an item to the table. All other attributes are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'NRFTHJL7EMMK17I1OM0S1QS8LBVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Fri, 03 Apr 2020 06:08:31 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'NRFTHJL7EMMK17I1OM0S1QS8LBVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '2745614147'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.put_item(\n",
    "    Item = {\n",
    "        \"job_title\" : \"Data Analyst\",\n",
    "        \"company_location\" : \"ano_Seattle\",\n",
    "        \"company\" : \"ano\",\n",
    "        \"location\" : \"Seattle\",\n",
    "        \"city\" : \"WA\",\n",
    "        \"description\" : \"With one application you can be considered for thousands of tech roles from leading companies on Seen. Seen by Indeed is a free service that connects you to opportunities that take you further in your career.\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Print out the item count in the table. It takes ~6 hrs for the correct count to reflect. \n",
    "#I just inserted the records so we are still seeing 0 in the count\n",
    "print(table.item_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get an item from the table\n",
    "\n",
    "We must specify the primary key values to read any item from jobs1 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'Redmond', 'job_title': 'Business Analyst', 'company': 'BCD', 'salary': None, 'zip_code': None, 'source': 'Indeed', 'reviews': '680 reviews', 'description': 'Cloud Hardware Infrastructure and Engineering Group is the engine that powers the cloud services. The team is responsible for designing, developing and maintaining the core infrastructure and foundational technologies for over 200 online businesses. We focus on smart growth with an emphasis on automation, data driven engineering, costeffectiveness and environmental sustainability. We are looking for a passionate, high energy individual to help build the End to End lifecycle that powers the worlds largest online services. This is a great opportunity to join a dynamic team and influence the way one of the worlds largest and fastest growing cloud environments is built and supported. As a critical part of the Cloud Hardware Infrastructure and Engineering team, this role will help define how we improve overall delivery and drive agility across the organization. We are all about improving quality delivery, change control, and efficient day to day operations. We operate in a hightech environment, laying the groundwork for scalable growth while delivering capacity and exceeding our customers expectations.\\r\\nResponsibilities\\r\\nSupport operationalizing the organization through data analysis.\\r\\nDrive best-in-class process systems solutions and strategy.\\r\\nRegularly communicate status to internal stakeholders, with efficient analysis of issues and potential direction. Document the risks and discuss mitigation plans with key stakeholders\\r\\nIdentify, develop, and management strategic business relationships, processes and programs.\\r\\nLead continuous improvement of business process and systems implementations, manage project governance, including portfolio planning and prioritization\\r\\nWork with engineering groups to define capabilities, schedules and resources needed\\r\\nStreamline reporting goals, develop and maintain comprehensive CHME KPIs for life cycle management and influence internal stakeholders to lead time improvements.\\r\\nRecommend internal and external process improvements and excellence conversations cross functionally to ensure we have optimized processes and aligned across partner teams\\r\\nQualifications\\r\\n\\r\\n1-3 years of experience in a high paced environment\\r\\nExperience working with engineering teams\\r\\nBS in Business, Finance, Data Analytics, Information Systems preferred.\\r\\nPreferred Qualifications:\\r\\nStrong Excel and Power BI skills\\r\\nAbility to transform complicated data sets into clear stories that are relevant to the business need\\r\\nExcellent communicator (written and verbal) with ability to create and deliver executive friendly communications on complex solutions\\r\\nAbility to interact with diverse technical and non-technical groups spanning all organizational levels\\r\\nStrong critical thinking, attention to detail and resolution in sometimes ambiguous situations\\r\\nMust be a someone who is proactive in identifying process challenges and proactively driving improvements\\r\\nAbility to effectively communicate and collaborate across internal organizations to drive the right decisions for Microsoft\\r\\nWork independently to balance multiple tasks and competing priorities simultaneously', 'state': 'WA', 'company_location': 'BCD_Redmond'}\n"
     ]
    }
   ],
   "source": [
    "response = table.get_item(\n",
    "    Key={\n",
    "        \"job_title\": \"Business Analyst\",\n",
    "        \"company_location\": \"BCD_Redmond\"\n",
    "    }\n",
    ")\n",
    "print(response['Item'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query from the table using key\n",
    "\n",
    "We can query the items from the table only using the partition key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = table.query(\n",
    "    KeyConditionExpression = Key(\"job_title\").eq(\"Data Analyst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst : ABC\n",
      "Data Analyst : WXY\n",
      "Data Analyst : ano\n"
     ]
    }
   ],
   "source": [
    "for i in response['Items']:\n",
    "    print(i['job_title'], \":\", i['company'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screenshot of the table from AWS\n",
    "\n",
    "![title](table_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
